{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ba2fa2c-bfec-408e-8126-620f48df2194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               title                                                   total_time                                                                                           image                                                                                                                                                                                                                                           ingredients rating_val rating_count     category cuisine                                                                diet  vegan  vegetarian                                                               url\n",
      "0  Avocado pasta with peas and mint   Prep Time: less than 30 mins | Cook Time: less than 10 mins  https://ichef.bbci.co.uk/food/ic/food_16x9_1600/recipes/avocado_pasta_with_peas_31700_16x9.jpg  375g/13oz pasta, such as penne or fusilli1 large avocado (or 2 small) 2 garlic cloves2 tbsp coconut oil, meltedÂ½ tsp salt 1 lemon, juice and zest 6 fresh mint leaves150g/5Â½oz fresh peas (or frozen and defrosted) 1 large red chilli (optional)         4.0   37 ratings  Main course    None  Egg-free, Healthy, Nut-free, Pregnancy-friendly, Vegan, Vegetarian   True        True  https://www.bbc.co.uk/food/recipes/avocado_pasta_with_peas_31700\n",
      "                      title                                                   total_time                                                                                           image                                                                                                                                                                                                                              ingredients rating_val rating_count          category  cuisine                            diet  vegan  vegetarian                                                                url\n",
      "0  Easiest ever banana cake  Prep Time: less than 30 mins | Cook Time: 30 mins to 1 hour  https://ichef.bbci.co.uk/food/ic/food_16x9_832/recipes/easiest_ever_banana_cake_42108_16x9.jpg  3 very ripe medium bananas (around 225g/8oz peeled weight)3 large free-range eggs100g/3Â½oz soft light brown sugar150ml/5fl oz sunflower or vegetable oil275g/9Â¾oz white self-raising flour1 tsp ground mixed spice1 tsp baking powder        4.5  464 ratings  Cakes and baking  British  Pregnancy-friendly, Vegetarian  False        True  https://www.bbc.co.uk/food/recipes/easiest_ever_banana_cake_42108\n",
      "                               title                                                   total_time                                                                                    image                                                                                                                                                                                                                                                                                                                ingredients rating_val rating_count     category cuisine                                    diet  vegan  vegetarian                                                         url\n",
      "0  Whole chicken and chickpea roast   Prep Time: less than 30 mins | Cook Time: 30 mins to 1 hour  https://ichef.bbci.co.uk/food/ic/food_16x9_832/recipes/whole_chicken_and_54954_16x9.jpg  vegetable oil, for frying4 garlic cloves, crushed2 red onions, cut into chunks1 aubergine, cut into cubes2 x 400g tins chickpeas, drained and rinsed1 lemon, topped and tailed and thinly sliced2 tsp coriander seeds2 tsp cumin seeds1Â½ tsp salt2 tsp paprikaÂ½ tsp ground turmericwhole chicken, about 1.2kg/2lb 12oz         4.0    7 ratings  Main course    None  Egg-free, Nut-free, Pregnancy-friendly  False       False  https://www.bbc.co.uk/food/recipes/whole_chicken_and_54954\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Part 1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define column names for the DataFrame\n",
    "columns = ['title', 'total_time', 'image', 'ingredients', 'rating_val', 'rating_count', 'category', \n",
    "           'cuisine', 'diet', 'vegan', 'vegetarian', 'url']\n",
    "\n",
    "def collect_page_data(url):\n",
    "    try:\n",
    "        # Fetch the webpage content\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        row_data = []\n",
    "\n",
    "        # Extract recipe title\n",
    "        heading = soup.find('h1')\n",
    "\n",
    "        # Extract image URL\n",
    "        image = soup.find('img').get('src')\n",
    "\n",
    "        # Extract ingredients list\n",
    "        ingredients = soup.find('ul', class_=\"ssrcss-1ynsflq-UnorderedList e1q8fsc70\").text\n",
    "\n",
    "        # Extract preparation and cooking time\n",
    "        first_div = soup.find('dl', class_=\"ssrcss-160xqny-Wrapper e85aajs0\")\n",
    "        first_div_split = list(first_div.stripped_strings)\n",
    "        \n",
    "        total_time = \"Prep Time: \"\n",
    "        diet = \"\"\n",
    "        vegan = False\n",
    "        vegetarian = False\n",
    "\n",
    "        for i in range(len(first_div_split)):\n",
    "            if i == 1:\n",
    "                total_time += first_div_split[i] + \" | Cook Time: \"\n",
    "            if i == 3:\n",
    "                total_time += first_div_split[i]\n",
    "            if i > 7:\n",
    "                diet += first_div_split[i] + (\", \" if i + 1 != len(first_div_split) else \"\")\n",
    "\n",
    "            # Check for dietary tags\n",
    "            if first_div_split[i] == \"Vegan\":\n",
    "                vegan = True\n",
    "            if first_div_split[i] == \"Vegetarian\":\n",
    "                vegetarian = True\n",
    "\n",
    "        # Extract rating value and count\n",
    "        rating_val = soup.find('span', class_='').text.strip()\n",
    "        ratings_count = soup.find('span', class_='').find_next().find_next().text.strip()\n",
    "\n",
    "        # Extract category and cuisine from JSON data\n",
    "        script_tag = soup.find(\"script\", {\"type\": \"application/ld+json\"})\n",
    "        json_data = json.loads(script_tag.string)\n",
    "        \n",
    "        category = next((item.get(\"recipeCategory\") for item in json_data[\"@graph\"] if item[\"@type\"] == \"Recipe\"), None)\n",
    "        cuisine = next((item.get(\"recipeCuisine\") for item in json_data[\"@graph\"] if item[\"@type\"] == \"Recipe\"), None)\n",
    "\n",
    "        # Store extracted data\n",
    "        row_data.extend([heading.text, total_time, image, ingredients, rating_val, ratings_count,\n",
    "                         category, cuisine, diet, vegan, vegetarian, url])\n",
    "\n",
    "        # Save data to a CSV file\n",
    "        df = pd.DataFrame(columns=columns)\n",
    "        df.loc[0] = row_data\n",
    "        df.to_csv('recipe.csv')\n",
    "\n",
    "        # Print the extracted data\n",
    "        print(df.to_string())\n",
    "\n",
    "    except:\n",
    "        print(\"Failed to fetch data for:\", url)\n",
    "\n",
    "\n",
    "# Define recipe URLs to scrape\n",
    "url = \"https://www.bbc.co.uk/food/recipes/avocado_pasta_with_peas_31700\"\n",
    "url2 = \"https://www.bbc.co.uk/food/recipes/easiest_ever_banana_cake_42108\"\n",
    "url3 = \"https://www.bbc.co.uk/food/recipes/whole_chicken_and_54954\"\n",
    "\n",
    "# Collect data from each URL\n",
    "collect_page_data(url)\n",
    "collect_page_data(url2)\n",
    "collect_page_data(url3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5e98010-dbfd-45e8-b391-9cd6a75f46ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0           id   rating_avg   rating_val   total_time\n",
      "count  3293.000000  3293.000000  3293.000000  3293.000000  3293.000000\n",
      "mean   1646.000000  1647.000000     4.497432    12.038567   127.227452\n",
      "std     950.751545   950.751545     0.611602    25.221305   156.363779\n",
      "min       0.000000     1.000000     1.000000     1.000000    30.000000\n",
      "25%     823.000000   824.000000     4.250000     3.000000    60.000000\n",
      "50%    1646.000000  1647.000000     4.666667     6.000000    90.000000\n",
      "75%    2469.000000  2470.000000     5.000000    13.000000   150.000000\n",
      "max    3292.000000  3293.000000     5.000000   776.000000   840.000000\n",
      "                                    title  rating_avg  rating_val\n",
      "1646                 Ma's macadamia salad         5.0           1\n",
      "2419                              Sangria         5.0           3\n",
      "842          Cranberry and grape focaccia         5.0           1\n",
      "840   Cranberry and chilli brioche wreath         5.0           2\n",
      "1773               Middle Eastern lentils         5.0           7\n",
      "838                  Crackling pork belly         5.0           1\n",
      "837                     Crackle top bread         5.0           3\n",
      "836                         Crab linguine         5.0           4\n",
      "2411    Salted caramel and coffee éclairs         5.0           3\n",
      "834               Crab and scallop Mornay         5.0           1\n",
      "title\n",
      "‘Dirty’ veggie starter platter                                  5.0\n",
      "Cranberry and chilli brioche wreath                             5.0\n",
      "Cottage pie jacket potatoes                                     5.0\n",
      "Coronation prawn vol-au-vents                                   5.0\n",
      "Penne with roasted vegetable and tomato sauce                   5.0\n",
      "Peppered fillet of beef with mustard, thyme and brandy sauce    5.0\n",
      "Corned beef hash with beer-battered onion rings                 5.0\n",
      "Peppers with chickpeas and harissa                              5.0\n",
      "Corned beef and onion pie                                       5.0\n",
      "Perfect roast duck with bread sauce                             5.0\n",
      "Name: rating_avg, dtype: float64\n",
      "Bootstrap Means: [4.56891603829, 4.314698816359999, 4.54761304067, 4.557517209319999, 4.48446813162, 4.4944255646, 4.57672771479, 4.39979422361, 4.55921733873, 4.50106286139, 4.566237628140001, 4.42680538978, 4.55224535553, 4.511760055620001, 4.55786070904, 4.50015798681, 4.44308036107, 4.5583657424399995, 4.587845943930001, 4.54623539162, 4.42382240324, 4.52190445584, 4.4881674434, 4.48932930614, 4.504055718669999, 4.49734274767, 4.5884427400800005, 4.45832418484, 4.470620601859999, 4.46160439729, 4.42914186417, 4.52429617651, 4.51745317189, 4.45340323732, 4.48503092746, 4.52538717851, 4.42872153389, 4.48092383899, 4.36251922748, 4.47695325809, 4.52816692558, 4.37838247393, 4.51250732107, 4.47236691001, 4.51717853332, 4.46280376722, 4.445422559920001, 4.52824649612, 4.47696474666, 4.538527951160001, 4.37477434339, 4.5280090824500006, 4.51525266934, 4.510691146190001, 4.4845519540200005, 4.51641094685, 4.57593672204, 4.34083737543, 4.38746038047, 4.56778072299, 4.444104396709999, 4.48319678922, 4.54478645262, 4.43567299848, 4.42723367145, 4.6005958826199995, 4.50859842335, 4.48028515386, 4.39367818052, 4.520233552530001, 4.55405165899, 4.55632529358, 4.54030805535, 4.47453979401, 4.55838186164, 4.46468852148, 4.40343887775, 4.46176584455, 4.439558841079999, 4.52923580435, 4.43224989751, 4.47670750076, 4.53428059009, 4.50497432496, 4.48457872223, 4.582910775919999, 4.47611317536, 4.42939022835, 4.47558662281, 4.50301238484, 4.4419716110100005, 4.48561114904, 4.52087259149, 4.534121284739999, 4.5131457285, 4.52421801163, 4.51847478284, 4.47268834538, 4.433167950530001, 4.424209890749999, 4.420524810499999, 4.39530097758, 4.591973715579999, 4.58210423799, 4.5745678667, 4.51690097666, 4.45850378594, 4.50551090826, 4.535645368, 4.47738408487, 4.5136185929, 4.50772538501, 4.49457939993, 4.473202789789999, 4.6094647246800005, 4.477294132329999, 4.51337885384, 4.46341259121, 4.423647246060001, 4.52349973529, 4.62743999243, 4.522170878080001, 4.46814591929, 4.56165166375, 4.56460664474, 4.4448068669200005, 4.57145126095, 4.50646071198, 4.56255082933, 4.3934681185999995, 4.516557998250001, 4.45520503849, 4.58855471915, 4.399463470540001, 4.56095802722, 4.423298985789999, 4.47711863894, 4.58327974548, 4.468051815360001, 4.52837639617, 4.51628680777, 4.5153533531, 4.32676254032, 4.58194739994, 4.40807045201, 4.412611492469999, 4.389088674659999, 4.43349154307, 4.47653613986, 4.4356752467, 4.4772386287799995, 4.588259346560001, 4.57527151947, 4.530066235750001, 4.35936457156, 4.451772375149999, 4.4313497633, 4.48827436301, 4.4572500691, 4.49121116484, 4.47353586369, 4.527504812230001, 4.4392614625, 4.42538754686, 4.50563837722, 4.528751626230001, 4.4355538896999995, 4.45643339934, 4.4325821871199995, 4.6225114191, 4.40697935223, 4.46011094015, 4.48359821658, 4.53356991041, 4.63465049878, 4.533211820449999, 4.60453353104, 4.595542345199999, 4.55427426924, 4.55658102653, 4.55345965668, 4.60072761482, 4.5431503714299994, 4.493192135239999, 4.582777291709999, 4.515874489310001, 4.46272606999, 4.52620175621, 4.53818193752, 4.545192105099999, 4.495145562640001, 4.4904603979, 4.517346365020001, 4.442599814659999, 4.53832214989, 4.5098978552, 4.57278315967, 4.44332010407, 4.59660713787, 4.470420256130001, 4.5016080988, 4.513714601299999, 4.474146252930001, 4.613235921639999, 4.631418083590001, 4.53200567379, 4.50013796779, 4.5267256758, 4.3916065776, 4.463958451189999, 4.45981110974, 4.60409811978, 4.4382649793499995, 4.54793616354, 4.53424070392, 4.47042475501, 4.36456451345, 4.54137016819, 4.585174583420001, 4.32872683971, 4.40891401594, 4.3102618989499994, 4.48250952933, 4.54316887846, 4.547148288350001, 4.39117629985, 4.42940456873, 4.5182610062499995, 4.52742837532, 4.51949218396, 4.4342592623399995, 4.55035349993, 4.418232843919999, 4.437050801560001, 4.47572778774, 4.47421489543, 4.53167868969, 4.5402704133, 4.51545628166, 4.45940565672, 4.46599471525, 4.4431128247, 4.37523197623, 4.47083741192, 4.52124931815, 4.5054619551599995, 4.51697061802, 4.47470661275, 4.4142766979, 4.438935643590001, 4.45954227317, 4.47860077275, 4.493217867779999, 4.372390446230001, 4.50841890237, 4.536384925989999, 4.43518816334, 4.528646032089999, 4.61396555382, 4.43313117226, 4.51877206325, 4.54722937252, 4.49125258097, 4.52091436695, 4.55193164971, 4.51338075741, 4.38902842782, 4.401942710269999, 4.5857122723599995, 4.6081060609, 4.4533435375999995, 4.54676050412, 4.4025885658099995, 4.4870315193, 4.52198858233, 4.49857333064, 4.529749202670001, 4.495537289889999, 4.46509411042, 4.54312820172, 4.49319696371, 4.56409965381, 4.51532365716, 4.560257003169999, 4.48275996824, 4.530006298549999, 4.471950628119999, 4.4390584381, 4.44542615553, 4.36383087973, 4.40848202071, 4.5246533928399995, 4.4757036299, 4.605011802479999, 4.5241368778, 4.40535802809, 4.545041147, 4.54502925241, 4.57045611237, 4.55957183288, 4.507877565929999, 4.5160983006, 4.5457973402, 4.49310699771, 4.48396691386, 4.55383242029, 4.498360601860001, 4.46285886276, 4.4415935630500005, 4.46526230197, 4.51985796353, 4.2928480349, 4.53021799024, 4.598593570769999, 4.491749100319999, 4.503565546370001, 4.54289742177, 4.4822219170799995, 4.60987885442, 4.482247200180001, 4.547054019619999, 4.56233554388, 4.51696349138, 4.45812264998, 4.4324464484999995, 4.5291809468799995, 4.55791883916, 4.494042737259999, 4.60031601659, 4.47656050942, 4.54722507507, 4.49048750868, 4.50781810631, 4.62463987456, 4.51104546026, 4.45148337759, 4.44559641983, 4.51331717302, 4.48789320366, 4.56103971771, 4.48067074842, 4.456112062740001, 4.521064486589999, 4.56961151047, 4.538831355939999, 4.39226405926, 4.59468709372, 4.38901232628, 4.50753184426, 4.51778694766, 4.60622754854, 4.47635079806, 4.35457465964, 4.45282335667, 4.39972582165, 4.480737649329999, 4.43447037231, 4.4040537116900005, 4.42250099993, 4.47917728636, 4.49558154887, 4.58615676061, 4.60440690559, 4.29405190388, 4.49223019858, 4.5329921213999995, 4.58468833359, 4.4835171571, 4.500464511130001, 4.51951290571, 4.49805383062, 4.579139122179999, 4.5534223670400005, 4.45489572176, 4.42872434286, 4.49826444557, 4.50731289794, 4.49320144254, 4.50536505811, 4.50551433487, 4.506487308960001, 4.46890911642, 4.4223477202099994, 4.5061877458, 4.601327262259999, 4.49391891525, 4.47668022652, 4.5040165310099995, 4.51281229421, 4.33966224176, 4.4688603547, 4.52393729636, 4.43208836042, 4.4926129109, 4.557702451, 4.5302391555899995, 4.445218261, 4.54246316086, 4.51902034022, 4.62583174484, 4.463850547069999, 4.5370048806, 4.48342260854, 4.52314225737, 4.49971114553, 4.48089325466, 4.56394317652, 4.51196675725, 4.48996566993, 4.59089992259, 4.4757405946099995, 4.44601780459, 4.43976782489, 4.35924241409, 4.44769833911, 4.42051517136, 4.59789528789, 4.39056102497, 4.48597055338, 4.52735148772, 4.53336902332, 4.44210869493, 4.51722319502, 4.48394643521, 4.47552942921, 4.61001358511, 4.4418151908, 4.55893605318, 4.507271201879999, 4.53936973884, 4.561798377590001, 4.43838715977, 4.5430447431, 4.37411737525, 4.476131284679999, 4.45608473542, 4.53204354582, 4.52244702776, 4.42994671725, 4.5609281508, 4.52939662683, 4.529938406309999, 4.48179888121, 4.48997880088, 4.4316330755, 4.53784199176, 4.44084969659, 4.49683151004, 4.55556072865, 4.44122293084, 4.49613584351, 4.5206461406, 4.50830233921, 4.418720871180001, 4.55862464031, 4.42111501984, 4.54770183806, 4.54123701765, 4.477110778349999, 4.4810148734199995, 4.5225754856, 4.55150447579, 4.598523277009999, 4.49547067816, 4.56078222718, 4.5025260093199995, 4.531812384169999, 4.6041528530599996, 4.464945595390001, 4.435806858109999, 4.45761949797, 4.40178969595, 4.56109441656, 4.37671242829, 4.43905147985, 4.54676730936, 4.62060793614, 4.547218120689999, 4.51189102503, 4.489313602539999, 4.498006488070001, 4.4868343852, 4.53288176246, 4.54401529868, 4.4450229088299995, 4.457498180959999, 4.56578265896, 4.47042747333, 4.27871451166, 4.52668762379, 4.55810778461, 4.46000219996, 4.491197351319999, 4.509509947750001, 4.531034758, 4.580914147920001, 4.499654369590001, 4.45884333659, 4.51622457512, 4.40307903944, 4.4773435342, 4.3779490353, 4.48903842213, 4.580657759999999, 4.4544998193500005, 4.62223905528, 4.487859296189999, 4.49767945973, 4.47457893529, 4.39941135665, 4.5162028349, 4.5006808973900005, 4.461825646099999, 4.5675056324400005, 4.4865186605, 4.57782694466, 4.548906739, 4.52650608464, 4.572499888419999, 4.56047273708, 4.48885646383, 4.47764262421, 4.526701771220001, 4.56153911824, 4.488973990020001, 4.46282003288, 4.62460172376, 4.57530937908, 4.57580224428, 4.438088261230001, 4.46294205602, 4.50371286475, 4.59979581628, 4.494729110820001, 4.57244541696, 4.53949357444, 4.51854564138, 4.50902467715, 4.50223822777, 4.48247566241, 4.5552504669500005, 4.57088712098, 4.51210172773, 4.52691196743, 4.590502943140001, 4.517253165910001, 4.5203000382, 4.53477034853, 4.59804520702, 4.509337682940001, 4.475390094400001, 4.546751513719999, 4.48433755645, 4.44432752213, 4.544650024309999, 4.45648032282, 4.49934813275, 4.55365051069, 4.441449588499999, 4.48337234174, 4.4372045386700005, 4.62574531347, 4.4665225391400005, 4.45263395056, 4.49200333478, 4.42047041691, 4.46220791667, 4.533550914309999, 4.52597418839, 4.53933068818, 4.489728597439999, 4.49325703108, 4.35523286698, 4.450482093840001, 4.644114203899999, 4.60711108588, 4.55980689305, 4.52182811964, 4.54235140609, 4.563684983709999, 4.51843686654, 4.54168943641, 4.61891014994, 4.431824227020001, 4.3937650260800005, 4.54245086485, 4.50945230032, 4.51266207491, 4.49662458261, 4.54658931154, 4.40249092903, 4.48084145205, 4.47666511014, 4.52117754995, 4.51575434472, 4.424093426130001, 4.51021449342, 4.55372153144, 4.45548622202, 4.45131766902, 4.52980717803, 4.477001734149999, 4.5627766946, 4.40307965292, 4.52829076159, 4.49862016356, 4.50424101836, 4.4933244736099995, 4.539202272330001, 4.41299037693, 4.50227111365, 4.51740772964, 4.565315202479999, 4.54602440567, 4.537230431079999, 4.483987372890001, 4.51879996056, 4.419396835940001, 4.465183122250001, 4.437146199560001, 4.53015443951, 4.494175026579999, 4.48816276402, 4.541099009829999, 4.4449597041599995, 4.54490340282, 4.526276846439999, 4.44980042531, 4.604556936190001, 4.47614759676, 4.46134320184, 4.45178857153, 4.59736072139, 4.52802336044, 4.38521936083, 4.50982003442, 4.45620468994, 4.5589396104999995, 4.45280628812, 4.550726833439999, 4.45511560693, 4.47783223699, 4.523237602629999, 4.49244708469, 4.46529491373, 4.338158083010001, 4.5259663761099995, 4.4775557802399995, 4.39473463305, 4.615346490319999, 4.4332339882700005, 4.57236964283, 4.51605710553, 4.57204514971, 4.40781293848, 4.41147735066, 4.49365612495, 4.5447668315300005, 4.50692997565, 4.44897767203, 4.45226962864, 4.55090168305, 4.393523543300001, 4.51853971928, 4.548642684300001, 4.4836680285199995, 4.40434505351, 4.49667491966, 4.54127897473, 4.4733375396, 4.334322907, 4.459686641889999, 4.48373852377, 4.56449423631, 4.40041618595, 4.470019928770001, 4.465951470829999, 4.54181159805, 4.48035728808, 4.51349177158, 4.442824738549999, 4.51286129273, 4.48106463977, 4.52267632049, 4.53833366965, 4.495301092190001, 4.3596717737, 4.47833924921, 4.44704409957, 4.4807500975100005, 4.48142476071, 4.43324017566, 4.47562323633, 4.52709122358, 4.400099039490001, 4.5144794334, 4.49395532371, 4.40236185046, 4.49404987238, 4.47606721007, 4.394661724630001, 4.39684793493, 4.460146491380001, 4.51438593628, 4.54010344557, 4.56463263171, 4.40978332247, 4.51162687193, 4.58891983055, 4.52172916577, 4.45129274431, 4.53759066798, 4.55179056105, 4.4483162176299995, 4.47127522036, 4.44104542849, 4.58259840997, 4.56619255415, 4.34219454293, 4.61523292236, 4.42479966484, 4.51088214442, 4.39347268175, 4.45603667287, 4.4979958591399996, 4.51621667389, 4.45623300093, 4.4377996501400006, 4.51257185182, 4.5642381711499995, 4.61134709685, 4.6067580579100005, 4.48828598117, 4.53188162898, 4.55297191223, 4.41537216645, 4.44823279493, 4.48783947014, 4.5079793126, 4.46381787236, 4.516637944809999, 4.38564252638, 4.5906495198799995, 4.478937756960001, 4.56674580691, 4.50317327231, 4.490067181340001, 4.377919810240001, 4.50412869728, 4.51915338477, 4.41792987359, 4.535013537219999, 4.52564302911, 4.416375072529999, 4.43364685121, 4.36726727113, 4.413970117830001, 4.41972843181, 4.44804416468, 4.50455491877, 4.45245135496, 4.38064721735, 4.446928723289999, 4.520138275369999, 4.54183370081, 4.50683357763, 4.55559534407, 4.5218508775099995, 4.57471746502, 4.49214122554, 4.50310416371, 4.38828375711, 4.49718840699, 4.51930868073, 4.55315065371, 4.51942927904, 4.4424215582599995, 4.5018270654400006, 4.535466700500001, 4.43858918415, 4.3900855965700005, 4.507808316879999, 4.493622240140001, 4.55218058244, 4.4073191528799995, 4.47638741065, 4.52244142084, 4.4846945182899995, 4.50407467258, 4.47887520925, 4.505983037570001, 4.39399642767, 4.45572474682, 4.46631602181, 4.410043642860001, 4.427384819669999, 4.4124041296000005, 4.59397018173, 4.5185884385, 4.59902215433, 4.6598680328699995, 4.4691287288399995, 4.526099466930001, 4.52098408626, 4.455550705169999, 4.4424748398, 4.5231900101799996, 4.55110978868, 4.51610710632, 4.51296893233, 4.4468319879700005, 4.57906643637, 4.53610552754, 4.54744087033, 4.49434475235, 4.4677567765, 4.63871313095, 4.48849289902, 4.49182742794, 4.58898271647, 4.478605283189999, 4.421725316620001, 4.47185316885, 4.48045651476, 4.50947476218, 4.4968646233700005, 4.5201771392, 4.5065810955500005, 4.5045177371700005, 4.47648120938, 4.50697454183, 4.41125430758, 4.5388240378199995, 4.48397718564, 4.41866833917, 4.50746639569, 4.43209068255, 4.56940783175, 4.59926845878, 4.5163779352099995, 4.558833642840001, 4.45763776782, 4.5797975124, 4.54930900892, 4.51919408477, 4.5377888545500005, 4.55121960887, 4.5558194418, 4.45355661801, 4.35670578073, 4.521523955259999, 4.44389495886, 4.5171686921, 4.390272084279999, 4.477547044980001, 4.49808242855, 4.52144911008, 4.54997608707, 4.52559511808, 4.48613369531, 4.504532887100001, 4.62382376376, 4.49797990474, 4.4765846702, 4.556789479260001, 4.44593680823, 4.55603631469, 4.51570718145, 4.52277692078, 4.61138618839, 4.44529845133, 4.48423051227, 4.5916110576, 4.59808443847, 4.46259027142, 4.49386867786, 4.61081501482, 4.53562753837, 4.47358162327, 4.5041716663399995, 4.45897724923, 4.504617284869999, 4.4721381868600005, 4.51130571716, 4.491064077139999, 4.5102054247500005, 4.520912330549999, 4.4882567273300005, 4.58406329494, 4.51845469204, 4.4466250554, 4.52632303347, 4.47539349292, 4.49907020333, 4.4703891996300005, 4.50754389736, 4.516346457760001, 4.43020183162, 4.4963583721400004, 4.58550418618, 4.5214495462399995, 4.5029788323, 4.52462011048, 4.6406002525600005, 4.442799561449999, 4.566055197759999, 4.53118905768, 4.59981989203, 4.4409098267300005, 4.50173874381, 4.4217887317499995, 4.488036274760001, 4.44392466164, 4.56780305351, 4.54936152329, 4.61707691339, 4.51266727304, 4.58191067089, 4.595730393419999, 4.54286903831, 4.5788402580600005, 4.45190157897, 4.55180745732, 4.50421220174, 4.5874640456, 4.482657381719999, 4.46169237024, 4.5651713978599995, 4.52196527749, 4.537332001559999, 4.42984824166, 4.55384462363, 4.40355802126, 4.57184848047, 4.48400382427, 4.402061176119999, 4.44328563793, 4.54515917532, 4.53345292756, 4.50217215962, 4.41089862476, 4.595782907000001, 4.597030622329999, 4.6677115424, 4.50824816519, 4.49939015198, 4.42370381613, 4.49798984316, 4.4810439549400005, 4.50649794695, 4.523816545720001, 4.46570978744, 4.57876752341, 4.53390732491, 4.48207736223, 4.50574145607, 4.46241771187, 4.53993881411, 4.54489887972, 4.4657757148399995, 4.48612340077, 4.53856444042, 4.56836650993, 4.60053944043, 4.45015210413, 4.56117858952, 4.55893230645, 4.54558900163, 4.47140111279, 4.47994473346, 4.51411716792, 4.542074678530001, 4.54768742459, 4.54286126693, 4.46442474619, 4.59410256968, 4.47436134718, 4.44133531971, 4.52078647263, 4.52505014943, 4.4503806289900005, 4.44130308159, 4.5638662824, 4.54545981845, 4.54456638261, 4.4440759772, 4.604108011609999, 4.58559513301, 4.5755077189, 4.43176695274, 4.57048902682, 4.489070635260001, 4.492010153370001, 4.45888749596, 4.48761631097, 4.5129941678800005, 4.51695551454, 4.4702653974399995, 4.441692488509999, 4.42694299191]\n",
      "Confidence Interval (Bootstrap): [4.37522054 4.61003362]\n",
      "count    3293.000000\n",
      "mean       12.038567\n",
      "std        25.221305\n",
      "min         1.000000\n",
      "25%         3.000000\n",
      "50%         6.000000\n",
      "75%        13.000000\n",
      "max       776.000000\n",
      "Name: rating_val, dtype: float64\n",
      "Cosine Similarity Matrix:\n",
      "[[1.         0.         0.         ... 0.09544271 0.0855921  0.03846154]\n",
      " [0.         1.         0.         ... 0.24525574 0.20619652 0.1111874 ]\n",
      " [0.         0.         1.         ... 0.05735393 0.         0.        ]\n",
      " ...\n",
      " [0.09544271 0.24525574 0.05735393 ... 1.         0.24779731 0.15907119]\n",
      " [0.0855921  0.20619652 0.         ... 0.24779731 1.         0.1711842 ]\n",
      " [0.03846154 0.1111874  0.         ... 0.15907119 0.1711842  1.        ]]\n",
      "\n",
      "Recommendations for 'Chicken and Coconut Curry':\n",
      "1. Vegan blackeye bean curry - https://www.bbc.co.uk/food/recipes/aromaticblackeyebean_73019\n",
      "2. Indian fish curry - https://www.bbc.co.uk/food/recipes/greencoconutfishcurr_86736\n",
      "3. Jamaican chicken curry - https://www.bbc.co.uk/food/recipes/curry_chicken_and_76534\n",
      "4. Leftover chicken curry - https://www.bbc.co.uk/food/recipes/roast_chicken_coconut_55460\n",
      "5. Chicken curry (shorshe murgi) - https://www.bbc.co.uk/food/recipes/shorshe_murgi_22125\n",
      "6. Chicken curry with basmati rice - https://www.bbc.co.uk/food/recipes/chicken_curry_with_83629\n",
      "7. Simple chicken curry - https://www.bbc.co.uk/food/recipes/simplegoanchickencur_67869\n",
      "8. Coconut fish curry - https://www.bbc.co.uk/food/recipes/coconutfishcurry_89979\n",
      "9. Chicken and vegetable balti - https://www.bbc.co.uk/food/recipes/chicken_and_vegetable_65850\n",
      "10. Goan fish curry - https://www.bbc.co.uk/food/recipes/goan_fish_curry_79255\n"
     ]
    }
   ],
   "source": [
    "#Part 2(Q1-Q3)\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"recipes.csv\")\n",
    "df_cleaned = df.dropna()\n",
    "print(df_cleaned.describe())\n",
    "\n",
    "top_10 = df_cleaned.sort_values(by=\"rating_avg\", ascending=False).head(10)\n",
    "print(top_10[['title', 'rating_avg', 'rating_val']])\n",
    "\n",
    "average_ratings = df.groupby('title')['rating_avg'].mean()\n",
    "top_10_recipes = average_ratings.sort_values(ascending=False).head(10)\n",
    "print(top_10_recipes)\n",
    "matplotlib.use('TkAgg')\n",
    "# TkAgg creates the graph outside python.\n",
    "bootstraps_size = 1000\n",
    "sample_size = 100\n",
    "bootstrap_samples = []\n",
    "for i in range(bootstraps_size):\n",
    "    sample = df.sample(n=sample_size, replace=True)['rating_avg']\n",
    "    bootstrap_samples.append(sample.mean())\n",
    "bootstrap_means = [np.mean(bootstrap_sample) for bootstrap_sample in bootstrap_samples]\n",
    "confidence_interval_bootstrap = np.percentile(bootstrap_means, [2.5, 97.5])\n",
    "print(f\"Bootstrap Means: {bootstrap_means}\")\n",
    "print(f\"Confidence Interval (Bootstrap): {confidence_interval_bootstrap}\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_cleaned['rating_val'], df_cleaned['rating_avg'], alpha=0.5)\n",
    "plt.xlabel('Ratings Frequency')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.title('Ratings vs. Ratings Frequency')\n",
    "plt.show()\n",
    "\n",
    "print(df['rating_val'].describe())\n",
    "# Example threshold, as the average is 12, anything under 12 should be can be considered as not significant.\n",
    "\n",
    "\n",
    "#Q4\n",
    "#2.4a\n",
    "features=['title','rating_avg','rating_val','total_time','category','cuisine', 'ingredients']\n",
    "\n",
    "#Creating a daraframe from the CSV file\n",
    "df = pd.read_csv('recipes.csv')\n",
    "\n",
    "# Adding the combined_features column\n",
    "df['combined_features'] = df[features].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "\n",
    "#2.4b\n",
    "# Creating a CountVectorizer object and computing the cosine similarity matrix\n",
    "#initializing the CountVectorizer\n",
    "CountVectorizer1 = CountVectorizer()\n",
    "\n",
    "#Fitting and transforming the combined_features column to create a count matrix\n",
    "\n",
    "count_matrix = CountVectorizer1.fit_transform(df['combined_features'])\n",
    "\n",
    "#Computing the cosine similarity matrix from the count matrix\n",
    "cosine_sim_matrix = cosine_similarity(count_matrix)\n",
    "\n",
    "# Displaying the cosine similarity matrix\n",
    "print(\"Cosine Similarity Matrix:\")\n",
    "print(cosine_sim_matrix)\n",
    "\n",
    "\n",
    "#2.4c\n",
    "\n",
    "# Recommendation function with URLs\n",
    "def get_recommendations(title, cosine_sim_matrix, df):\n",
    "    # Ensure title matching is case-insensitive and strip extra spaces\n",
    "    title = title.lower().strip()\n",
    "\n",
    "    # Check if the title exists in the DataFrame\n",
    "    if title not in df[\"title\"].str.lower().values:\n",
    "        return [\"Recipe not found. Please try a different title.\"]\n",
    "\n",
    "    # Get the index of the recipe that matches the title\n",
    "    idx = df[df['title'].str.lower() == title].index[0]\n",
    "\n",
    "    # Get the pairwise similarity scores of all recipes with that recipe\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
    "\n",
    "    # Sort the recipes based on similarity scores in descending order\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the indices of the top 10 most similar recipes\n",
    "    sim_scores = sim_scores[1:11]  # Exclude the input recipe itself\n",
    "    \n",
    "    # Get the recipe indices\n",
    "    recipe_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Get the top 10 most similar recipes and their URLs\n",
    "    recommended_titles = df[\"title\"].iloc[recipe_indices].tolist()\n",
    "    recommended_urls = df[\"recipe_url\"].iloc[recipe_indices].tolist()\n",
    "\n",
    "    # Zip function is used to combine the 2 above lists to a list of tuples\n",
    "    return list(zip(recommended_titles, recommended_urls))\n",
    "\n",
    "#Test\n",
    "recipe_title = \"Chicken and Coconut Curry\"\n",
    "recommendations = get_recommendations(recipe_title, cosine_sim_matrix, df)\n",
    "\n",
    "# Print the recommendations with URLs\n",
    "print(f\"\\nRecommendations for '{recipe_title}':\")\n",
    "for i, (title, url) in enumerate(recommendations, start=1):\n",
    "    print(f\"{i}. {title} - {url}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "105ae026-11a4-483e-94d7-d7d7c09d8ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for 'Chicken and Coconut Curry':\n",
      "1. Vegan blackeye bean curry - https://www.bbc.co.uk/food/recipes/aromaticblackeyebean_73019\n",
      "2. Indian fish curry - https://www.bbc.co.uk/food/recipes/greencoconutfishcurr_86736\n",
      "3. Indian-spiced lamb shoulder with Bombay potatoes - https://www.bbc.co.uk/food/recipes/indian-spiced_lamb_48529\n",
      "4. Lamb madras with bombay potatoes - https://www.bbc.co.uk/food/recipes/lamb_madras_with_bombay_09160\n",
      "5. Jerk chicken thighs - https://www.bbc.co.uk/food/recipes/spicyjerkchickenthig_89120\n",
      "6. Roast chicken thighs with lentils and mint yoghurt - https://www.bbc.co.uk/food/recipes/roast_spiced_chicken_75133\n",
      "7. Softened sweet onion and crisp fried fish - https://www.bbc.co.uk/food/recipes/softened_sweet_onion_and_80481\n",
      "8. Chicken jalfrezi - https://www.bbc.co.uk/food/recipes/chickenjalfrezi_91772\n",
      "9. Dry curry of cabbage, carrot and coconut (Thoran)  - https://www.bbc.co.uk/food/recipes/dry_curry_of_cabbage_71527\n",
      "10. Indian chicken stew - https://www.bbc.co.uk/food/recipes/koliishtewchickenste_87479\n",
      "\n",
      "Recommendations for 'Anchovy and sage crisps':\n",
      "1. Scotch eggs (Similarity: 0.60)\n",
      "2. Prawn tempura (Similarity: 0.59)\n",
      "3. Parmesan shortbreads (Similarity: 0.59)\n",
      "4. How to make pancakes (Similarity: 0.55)\n",
      "5. Bacon and egg canapés  (Similarity: 0.54)\n",
      "6. Goats' cheese and shallot tarts (Similarity: 0.52)\n",
      "7. Breaded chicken nuggets  (Similarity: 0.51)\n",
      "8. Chorizo and lemongrass pastry puff scrolls (Similarity: 0.51)\n",
      "9. Stilton puffs (Similarity: 0.51)\n",
      "10. Sun-dried tomato and rosemary palmiers (Similarity: 0.49)\n",
      "\n",
      "KNN - Recommendations for 'Chicken tikka masala':\n",
      "Butter chicken   \n",
      "Oven-fried chicken\n",
      "Easy tandoori chicken\n",
      "Pollack, chorizo and chickpea stew\n",
      "Tandoori chicken lollipop drumsticks with raita dip\n",
      "Chicken and chorizo stew\n",
      "Buttermilk chicken\n",
      "Cumin and yoghurt chicken with cucumber and dill salad\n",
      "Caribbean chicken and pumpkin curry\n",
      "Chicken shawarma\n",
      "\n",
      "KNN - Recommendations for 'Albanian baked lamb with rice':\n",
      "Recipe not found. Please try a different title.\n",
      "\n",
      "KNN - Recommendations for 'Baked salmon with chorizo rice':\n",
      "Crispy salmon, polenta chips and grilled asparagus\n",
      "Prawn jambalaya\n",
      "Pan-fried salmon with broccoli\n",
      "Chicken and chorizo paella\n",
      "Chicken stew with chorizo and beans\n",
      "Chicken and chorizo rice\n",
      "Smoked mackerel pilau rice\n",
      "Salmon fillets with herbs and red pepper\n",
      "Stuffed chicken thighs\n",
      "Risotto alla Parmigiana\n",
      "\n",
      "KNN - Recommendations for 'Almond lentil stew':\n",
      "Smoked pancetta and lentil soup\n",
      "Lentil soup\n",
      "Bolognese ragù with pappardelle \n",
      "Jollof rice\n",
      "Vegan moussaka \n",
      "How to make steak and ale pie\n",
      "Chicken, cider and apple casserole\n",
      "Pasta and bean soup (Pasta e fagioli)\n",
      "Vegetarian chilli\n",
      "Healthy bacon and lentil soup\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 5983: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 200\u001b[0m\n\u001b[0;32m    197\u001b[0m csv_reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(read_obj) \n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# convert string to list \u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m list_of_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(csv_reader) \n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m list_of_csv:\n\u001b[0;32m    203\u001b[0m     recipes\u001b[38;5;241m.\u001b[39mappend(i[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mcharmap_decode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,decoding_table)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 5983: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#Part 3\n",
    "#3.1\n",
    "def vec_space_method(recipe, df):\n",
    "    #Processing categorical and Numerical features\n",
    "    categorical_columns = [\"category\", \"cuisine\", \"ingredients\"]\n",
    "\n",
    "    #Numerical columns \n",
    "    numerical_columns = [\"rating_avg\", \"total_time\"]\n",
    "\n",
    "    #Vectorize categorical data(convert to text)\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "\n",
    "    #convert categorical columns into text\n",
    "    categorical_features = df[categorical_columns].apply(lambda x: \" \".join(x), axis=1)\n",
    "    categorical_matrix = vectorizer.fit_transform(categorical_features)\n",
    "\n",
    "    #Normalize the Numerical Features\n",
    "    #Ensure numerical columns are in appropriate format\n",
    "    numerical_data = df[numerical_columns].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    numerical_data = numerical_data.fillna(0)  # Handle NaN values by filling with 0 or mean\n",
    "\n",
    "    #Scale the numerical data to ensure uniformity in magnitude\n",
    "    scalar = StandardScaler()\n",
    "    numerical_matrix = scalar.fit_transform(numerical_data)\n",
    "\n",
    "    #Combine categorical and numerical\n",
    "    combined_matrix = np.hstack((categorical_matrix.toarray(), numerical_matrix))\n",
    "\n",
    "    #Compute the cosine similarity\n",
    "    cosine_sim_matrix = cosine_similarity(combined_matrix)\n",
    "\n",
    "\n",
    "    \n",
    "    #Find the index of the recipie\n",
    "    recipe = recipe.lower().strip()\n",
    "\n",
    "    if recipe not in df[\"title\"].str.lower().values:\n",
    "        return [\"Recipe not found. Please try a different title.\"]\n",
    "\n",
    "    # Get the index of the recipe that matches the title\n",
    "    idx = df[df[\"title\"].str.lower() == recipe].index[0]\n",
    "\n",
    "    #Compute Similarity Scores\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
    "\n",
    "    # Sort recipes based on similarity scores (highest similarity first)\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top 10 most similar recipes (excluding the input recipe itself)\n",
    "    sim_scores = sim_scores[1:11]  # Exclude the input recipe itself\n",
    "    recipe_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    #Retrieve the Titles and URLs of the Most Similar Recipes\n",
    "    recommended_titles = df[\"title\"].iloc[recipe_indices].tolist()\n",
    "    recommended_urls = df[\"recipe_url\"].iloc[recipe_indices].tolist()\n",
    "\n",
    "    # Return the top 10 most similar recipes with URLs\n",
    "    return list(zip(recommended_titles, recommended_urls))\n",
    "\n",
    "\n",
    "recipe_title = \"Chicken and Coconut Curry\"\n",
    "recommendations = vec_space_method(recipe_title, df)\n",
    "\n",
    "# Print the recommendations with URLs\n",
    "print(f\"Recommendations for '{recipe_title}':\")\n",
    "for i, (title, url) in enumerate(recommendations, start=1):\n",
    "    print(f\"{i}. {title} - {url}\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "#.3.2\n",
    "def knn_similarity(recipe,df):\n",
    "    #Processing categorical and Numerical features\n",
    "    categorical_columns = [\"category\", \"cuisine\", \"ingredients\"]\n",
    "\n",
    "    #Numerical columns \n",
    "    numerical_columns = [\"rating_avg\", \"total_time\"]\n",
    "\n",
    "    #Vectorize categorical data(convert to text)\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    #converts categorical columns into text\n",
    "    categorical_features = df[categorical_columns].apply(lambda x: \" \".join(x), axis=1)\n",
    "    categorical_matrix = vectorizer.fit_transform(categorical_features)\n",
    "\n",
    "    #Normalize the Numerical Features\n",
    "    #Ensure numerical columns are in appropriate format\n",
    "    numerical_data = df[numerical_columns].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    numerical_data = numerical_data.fillna(0)  # Handle NaN values by filling with 0 or mean\n",
    "\n",
    "\n",
    "    #Scales the numerical data to ensure uniformity in magnitude\n",
    "    scalar = StandardScaler()\n",
    "    numerical_matrix = scalar.fit_transform(numerical_data)\n",
    "\n",
    "    #Combines categorical and numerical\n",
    "    #function is used to combine categorical and numerical features into a single matrix\n",
    "    combined_matrix = np.hstack((categorical_matrix.toarray(), numerical_matrix))\n",
    "\n",
    "\n",
    "    #Finds the index of the recipie\n",
    "    recipe = recipe.lower().strip()\n",
    "\n",
    "    if recipe not in df[\"title\"].str.lower().values:\n",
    "        return [\"Recipe not found. Please try a different title.\"]\n",
    "    \n",
    "    # Finds the index of the given recipe\n",
    "    recipe_index = df[df[\"title\"].str.lower() == recipe].index[0]\n",
    "\n",
    "    #KNN Model\n",
    "\n",
    "    knn_model = NearestNeighbors(metric=\"cosine\", algorithm=\"auto\", n_neighbors=11, n_jobs=-1)\n",
    "    knn_model.fit(combined_matrix)\n",
    "\n",
    "    dist, ind =  knn_model.kneighbors(combined_matrix[recipe_index].reshape(1, -1), n_neighbors=11)\n",
    "    \n",
    "    # Gets the titles of the 10 most similar recipes (excluding the input recipe itself)\n",
    "    similar_recipes = [\n",
    "        (df.iloc[i][\"title\"], dist[0][j])\n",
    "        for j, i in enumerate(ind[0])\n",
    "        if i != recipe_index\n",
    "    ]\n",
    "\n",
    "    # Returns the top 10 most similar recipes\n",
    "    return similar_recipes[:10]\n",
    "\n",
    "#test\n",
    "recipe_title = \"Anchovy and sage crisps\"\n",
    "recommendations = knn_similarity(recipe_title, df)\n",
    "\n",
    "# Prints the recommendations\n",
    "print(f\"\\nRecommendations for '{recipe_title}':\")\n",
    "for i, (title, distance) in enumerate(recommendations, start=1):\n",
    "    print(f\"{i}. {title} (Similarity: {1 - distance:.2f})\")\n",
    "\n",
    "#3.3\n",
    "\n",
    "u1_recipes = []\n",
    "u2_recipes = []\n",
    "u3_recipes = []\n",
    "u4_recipes = []\n",
    "\n",
    "#Test\n",
    "recipe_title = \"Chicken tikka masala\"\n",
    "recommendations = knn_similarity(recipe_title, df)\n",
    "for i in recommendations:\n",
    "    u1_recipes.append(i[0])\n",
    "\n",
    "# Print the recommendations\n",
    "print(f\"\\nKNN - Recommendations for '{recipe_title}':\")\n",
    "for i, (title) in enumerate(recommendations, start=1):\n",
    "    print(f\"{title[0]}\")\n",
    "\n",
    "#Test\n",
    "recipe_title = \"Albanian baked lamb with rice\"\n",
    "recommendations = knn_similarity(recipe_title, df)\n",
    "for i in recommendations:\n",
    "    u2_recipes.append(i[0])\n",
    "\n",
    "# Print the recommendations\n",
    "print(f\"\\nKNN - Recommendations for '{recipe_title}':\")\n",
    "for i, (title) in enumerate(recommendations, start=1):\n",
    "    print(f\"{title}\")\n",
    "\n",
    "\n",
    "#Test\n",
    "recipe_title = \"Baked salmon with chorizo rice\"\n",
    "recommendations = knn_similarity(recipe_title, df)\n",
    "for i in recommendations:\n",
    "    u3_recipes.append(i[0])\n",
    "\n",
    "# Print the recommendations\n",
    "print(f\"\\nKNN - Recommendations for '{recipe_title}':\")\n",
    "for i, (title) in enumerate(recommendations, start=1):\n",
    "    print(f\"{title[0]}\")\n",
    "\n",
    "#Test\n",
    "recipe_title = \"Almond lentil stew\"\n",
    "recommendations = knn_similarity(recipe_title, df)\n",
    "for i in recommendations:\n",
    "    u4_recipes.append(i[0])\n",
    "\n",
    "# Print the recommendations\n",
    "print(f\"\\nKNN - Recommendations for '{recipe_title}':\")\n",
    "for i, (title) in enumerate(recommendations, start=1):\n",
    "    print(f\"{title[0]}\")\n",
    "  \n",
    "recipes = []\n",
    "with open('recipes.csv', 'r') as read_obj: \n",
    "    csv_reader = csv.reader(read_obj) \n",
    "  \n",
    "    # convert string to list \n",
    "    list_of_csv = list(csv_reader) \n",
    "  \n",
    "    for i in list_of_csv:\n",
    "        recipes.append(i[2])\n",
    "\n",
    "recipes.pop(0)\n",
    "print(recipes)\n",
    "\n",
    "U1 = [1 if recipe in u1_recipes else 0 for recipe in recipes]\n",
    "U2 = [1 if recipe in u2_recipes else 0 for recipe in recipes]\n",
    "U3 = [1 if recipe in u3_recipes else 0 for recipe in recipes]\n",
    "U4 = [1 if recipe in u4_recipes else 0 for recipe in recipes]\n",
    "cosine_similarity_matrix = cosine_similarity([U1, U2, U3, U4])\n",
    "print(cosine_similarity_matrix)\n",
    "\n",
    "num_users = 4\n",
    "total_similarity = 0\n",
    "pairwise_count = 0\n",
    "\n",
    "for i in range(num_users):\n",
    "    for j in range(i + 1, num_users):\n",
    "        total_similarity += cosine_similarity_matrix[i][j]\n",
    "        pairwise_count += 1\n",
    "\n",
    "# Compute average pairwise similarity\n",
    "average_similarity = total_similarity / pairwise_count\n",
    "\n",
    "print(f\"Average Pairwise Similarity: {average_similarity:.4f}\")\n",
    "\n",
    "# Evaluation:\n",
    "# KNN:\n",
    "# Using the test set provided with about 500 recommendations for each test, only 1501 recommendations are provided as “Albanian baked lamb with rice” generated no recommendations. 1103 of the recommended items were unique leading to a coverage of – (1102/3293) * 100 = 33.5% to 3 significant figures. This low value indicates that there is low coverage meaning that many recipes are not recommended, suggesting that the model is narrow or biased towards certain recipes. \n",
    "\n",
    "# In terms of personalization of the knn algorithm, using the same test cases, an average pairwise similarity value of 0.153 (to 3 significant figures) was obtained. This extremely low average similarity value indicates that the algorithm provides quite a high personalization for each user. This was done using 500 recommendations per user. However, when generating 3000 recommendations per user, a higher average similarity value of 0.458 was obtained. This value is still relatively low, so the algorithm is still quite personalized. However, judging from these changes in values, it appears as though; the higher the number of recommendations, the less personalized the algorithm will become.\n",
    "\n",
    "# Vector Space Method:\n",
    "# Using the same test set provided, I end up getting the exact same coverage of – (1102/3293) * 100 = 33.5% to 3 significant figures. No recommendations were provided for “Albanian baked lamb with rice” in this system as well. Additionally, the same number of unique results were provided. Not only that, but the same number of recommendations (including duplicates) were produced. Following this result, I decided to increase the number of recommendations (750 per user) to get a broader range of results, and I ended up with (1399/3293) * 100 = 42.5%. This indicates an increase in coverage as the number of recommendations increases, meaning there is better diversity, and a larger portion of the recipes are recommended. \n",
    "\n",
    "# Once again, similarly to coverage, the same values as the knn algorithm were obtained for personalization. Using 500 recommendations per user, an average similarity value of 0.153 (to 3 s.f.) was obtained and 0.458 for 3000 recommendations per user. Same conclusion as knn algorithm. Vector space algorithm will most likely become less personalized as the number of recommendations increases. \n",
    "\n",
    "\n",
    "#3.4\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as r\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "#Creating a dataframe from the CSV file\n",
    "df = pd.read_csv('recipes.csv')\n",
    "\n",
    "#Changing values of column\n",
    "df[\"rating_avg\"] = np.where(df['rating_avg'] > 4.2, 1, 0)\n",
    "\n",
    "features=['title','rating_avg','rating_val','total_time','category','cuisine', 'ingredients']\n",
    "\n",
    "x = df[features]\n",
    "y = df[\"rating_avg\"]\n",
    "\n",
    "# Combine features\n",
    "df[\"combined_features\"] = df[[\"category\", \"cuisine\", \"ingredients\"]].apply(lambda x: \" \".join(x), axis=1)\n",
    "\n",
    "#Vectorize data\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "x_cat = vectorizer.fit_transform(df['combined_features']).toarray()\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "x_num = scaler.fit_transform(df[[\"rating_avg\", \"total_time\"]])\n",
    "\n",
    "# Combine numerical and categorical features\n",
    "x_combined = np.hstack((x_num, x_cat))\n",
    "\n",
    "# Splitting into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_combined, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "# Creating and training prediction model\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Form predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Model evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Evaluation (Accuracy):\n",
    "# Using the knn algorithm and sklearn’s metric accuracy score, I ended up with an accuracy value of 0.993 to 3 significant figures. This value indicates an almost 100% correct prediction ratio which means that out all the recommendations, practically all of them are correct recommendations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46b875-3a1c-4e2d-b992-8b81cd9033e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
